{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9822139,"sourceType":"datasetVersion","datasetId":6022749}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:21:10.743977Z","iopub.execute_input":"2024-11-06T09:21:10.744449Z","iopub.status.idle":"2024-11-06T09:21:10.750485Z","shell.execute_reply.started":"2024-11-06T09:21:10.744402Z","shell.execute_reply":"2024-11-06T09:21:10.749148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the image using matplotlib\nimage = mpimg.imread('/kaggle/input/input-images/img.jpg')\n\nplt.imshow(image)\nplt.title('Image')\nplt.axis('off') ","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:28:48.443984Z","iopub.execute_input":"2024-11-06T09:28:48.444560Z","iopub.status.idle":"2024-11-06T09:28:49.160672Z","shell.execute_reply.started":"2024-11-06T09:28:48.444508Z","shell.execute_reply":"2024-11-06T09:28:49.159389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(image))\nprint(image.shape)\nprint(image.ndim)\nprint(image.size)\nprint(image.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:28:58.301772Z","iopub.execute_input":"2024-11-06T09:28:58.302296Z","iopub.status.idle":"2024-11-06T09:28:58.310595Z","shell.execute_reply.started":"2024-11-06T09:28:58.302250Z","shell.execute_reply":"2024-11-06T09:28:58.308998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convertir l'image en niveaux de gris\ngrayscale_image = np.mean(image, axis=2).astype(np.uint8)\nprint(\"Dimensions de l'image en niveaux de gris :\", grayscale_image.shape)\n\n# Afficher l'image en niveaux de gris\nplt.imshow(grayscale_image, cmap='gray')\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:29:08.704718Z","iopub.execute_input":"2024-11-06T09:29:08.705299Z","iopub.status.idle":"2024-11-06T09:29:08.963739Z","shell.execute_reply.started":"2024-11-06T09:29:08.705246Z","shell.execute_reply":"2024-11-06T09:29:08.962316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extraction de la région [100:400, 100:400] de l'image\nplt.imshow(image[300:450, 300:450, :])  \nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:29:14.353449Z","iopub.execute_input":"2024-11-06T09:29:14.354303Z","iopub.status.idle":"2024-11-06T09:29:14.506773Z","shell.execute_reply.started":"2024-11-06T09:29:14.354246Z","shell.execute_reply":"2024-11-06T09:29:14.505187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extraction d’une Région Spécifique de l'Image :\n\nUne partie de l'image (coordonnées [300:450, 300:450]) a été extraite et affichée pour une observation ciblée.","metadata":{}},{"cell_type":"code","source":"\n\n# Séparer les canaux RGB\nR = image[:, :, 0]\nG = image[:, :, 1]\nB = image[:, :, 2]\n\n# Préparer l'affichage des canaux et de l'image originale\noutput = [image, R, G, B]\ntitles = ['Original Image', 'R Channel', 'G Channel', 'B Channel']\n\n# Afficher l'image originale et les canaux en niveaux de gris\nplt.figure(figsize=(10, 10))\nfor i in range(4):\n    plt.subplot(2, 2, i + 1)\n    plt.axis('off')\n    plt.title(titles[i])\n    if i == 0:\n        plt.imshow(output[i])\n    else:\n        plt.imshow(output[i], cmap='gray')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:29:41.924726Z","iopub.execute_input":"2024-11-06T09:29:41.925225Z","iopub.status.idle":"2024-11-06T09:29:42.922414Z","shell.execute_reply.started":"2024-11-06T09:29:41.925172Z","shell.execute_reply":"2024-11-06T09:29:42.921157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Séparation des Canaux Rouge, Vert et Bleu (R, G, B)\n\n\nCanal Rouge (R) : Cette image représente uniquement l'intensité du rouge dans chaque pixel, tandis que les intensités vertes et bleues sont ignorées. Ainsi, les zones de l'image qui sont fortement rouges apparaissent plus claires dans le canal rouge, et les zones sans composant rouge apparaissent sombres.\n\nCanal Vert (G) : De la même manière, le canal vert affiche les intensités vertes des pixels. Les zones contenant une composante verte élevée sont plus claires, tandis que les autres restent sombres. Ce canal est souvent le plus détaillé, car les capteurs d'images sont généralement plus sensibles au vert (à cause de la structure des capteurs RGB où le vert est plus abondant).\n\nCanal Bleu (B) : Enfin, le canal bleu ne montre que les intensités bleues de chaque pixel. Les zones fortement bleues de l'image apparaissent plus lumineuses, tandis que celles qui contiennent peu ou pas de bleu sont sombres.","metadata":{}},{"cell_type":"code","source":"# Recombiner les canaux pour vérifier l'intégrité de l'image\nOutput = np.dstack((R, G, B))\nplt.imshow(Output)\nplt.axis('off')\nplt.title('Reconstructed Image')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:29:48.244254Z","iopub.execute_input":"2024-11-06T09:29:48.244694Z","iopub.status.idle":"2024-11-06T09:29:48.587353Z","shell.execute_reply.started":"2024-11-06T09:29:48.244651Z","shell.execute_reply":"2024-11-06T09:29:48.586119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Résultat de la recombinaison\nLa recombinaison des canaux a permis de vérifier que l'image pouvait être reconstruite à partir des canaux séparés.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Charger les deux images t4 et t5\nt4 = plt.imread('/kaggle/input/input-images/t4.jpg')\n\nt5 = plt.imread('/kaggle/input/input-images/t5.jpg')\n\n# Afficher les deux images côte à côte\nplt.figure(figsize=(10, 5))\n\n# Affichage de t4\nplt.subplot(1, 2, 1)\nplt.imshow(t4)\nplt.axis('off')\nplt.title('t4')\n\n# Affichage de t5\nplt.subplot(1, 2, 2)\nplt.imshow(t5)\nplt.axis('off')\nplt.title('t5')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:31:15.424459Z","iopub.execute_input":"2024-11-06T09:31:15.424932Z","iopub.status.idle":"2024-11-06T09:31:15.807630Z","shell.execute_reply.started":"2024-11-06T09:31:15.424889Z","shell.execute_reply":"2024-11-06T09:31:15.806562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n\n\n# Ensure both images are in the same format (e.g., float for arithmetic operations)\nt4 = t4.astype(float)\nt5 = t5.astype(float)\n\n# Subtract t4 from t5\nresult = t5 - t4\n\n# Clip the values to be in the valid range (0, 255) for display as an image\nresult = np.clip(result, 0, 255).astype(np.uint8)\n\n# Display the result\nplt.imshow(result)\nplt.axis('off')\nplt.title('Result of t5 - t4')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:31:45.965150Z","iopub.execute_input":"2024-11-06T09:31:45.965735Z","iopub.status.idle":"2024-11-06T09:31:46.222970Z","shell.execute_reply.started":"2024-11-06T09:31:45.965679Z","shell.execute_reply":"2024-11-06T09:31:46.221388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calcul de la Différence de Mouvement entre Deux Images (t4 et t5) :\n\nDeux images (t4 et t5) ont été chargées et la différence de pixel entre les deux images a été calculée.\n\nRésultat : Une image de \"différence de mouvement\" a été générée, représentant les changements entre les deux images.","metadata":{}},{"cell_type":"code","source":"# Displaying the images\nplt.figure(figsize=(15, 10))\n\n# Original image\nplt.subplot(2, 3, 1)\nplt.imshow(image.astype(np.uint8))\nplt.axis('off')\nplt.title('Original Image')\n\n# 1. Making the image darker\ndarker_image = np.clip(image - 50, 0, 255).astype(np.uint8)\n\n# Darker image\nplt.subplot(2, 3, 2)\nplt.imshow(darker_image)\nplt.axis('off')\nplt.title('Darker Image')\n\n# 2. Reducing the difference between light and dark areas (contrast reduction)\nmean = np.mean(image)\nreduced_contrast_image = np.clip((image - mean) * 0.5 + mean, 0, 255).astype(np.uint8)\n\n# Reduced contrast image\nplt.subplot(2, 3, 3)\nplt.imshow(reduced_contrast_image)\nplt.axis('off')\nplt.title('Reduced Contrast')\n\n# 3. Inverting the image (dark to light and vice versa)\ninverted_image = (255 - image).astype(np.uint8)\n\n# Inverted image\nplt.subplot(2, 3, 4)\nplt.imshow(inverted_image)\nplt.axis('off')\nplt.title('Inverted Image')\n\n\n# 4. Increasing brightness\nbrighter_image = np.clip(image + 50, 0, 255).astype(np.uint8)\n\n# Brighter image\nplt.subplot(2, 3, 5)\nplt.imshow(brighter_image)\nplt.axis('off')\nplt.title('Brighter Image')\n\n# 5. Increasing contrast\ncontrast_image = np.clip((image - mean) * 1.5 + mean, 0, 255).astype(np.uint8)\n\n# Increased contrast image\nplt.subplot(2, 3, 6)\nplt.imshow(contrast_image)\nplt.axis('off')\nplt.title('Increased Contrast')\n\n\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T09:31:54.604189Z","iopub.execute_input":"2024-11-06T09:31:54.605234Z","iopub.status.idle":"2024-11-06T09:31:56.542062Z","shell.execute_reply.started":"2024-11-06T09:31:54.605184Z","shell.execute_reply":"2024-11-06T09:31:56.540824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyse des Résultats pour Chaque Technique\n\nAssombrissement : L'image apparaît plus sombre, réduisant la visibilité des détails dans les zones moins éclairées. Cette technique pourrait être utile pour simuler des conditions de faible luminosité.\n\nRéduction de Contraste : Les zones sombres et claires deviennent moins distinctes. Cela peut être utile pour lisser les transitions dans des images avec des variations de luminosité trop marquées.\n\nInversion des Pixels : L'image ressemble à un négatif photographique, ce qui peut être utile pour l'analyse d'image ou pour des applications d'imagerie médicale.\n\nAugmentation de la Luminosité : Les détails sont mieux visibles dans les zones sombres, simulant une amélioration des conditions de luminosité.\n\nAugmentation du Contraste : Les zones sombres deviennent plus sombres et les zones claires plus claires, ce qui peut être utile pour accentuer les détails.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}